{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Meta-Heuristic Feature Selection for Compressed BERT Embeddings\n", "This notebook applies Genetic Algorithm (GA), Jaya, and Rabbit Optimization Algorithm (ROA) to select optimal features from CBAM-compressed BERT embeddings."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pickle\n", "from sklearn.model_selection import cross_val_score\n", "from sklearn.ensemble import GradientBoostingClassifier\n", "from sklearn.metrics import f1_score, matthews_corrcoef\n", "from sklearn.model_selection import train_test_split\n", "import random\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load compressed features\n", "with open(\"cbam_compressed_features.pkl\", \"rb\") as f:\n", "    data = pickle.load(f)\n", "    X = data['compressed_features']\n", "    y = data['y_train']"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Fitness evaluation: train a GBM and return average F1 score on hold-out split\n", "def evaluate_fitness(X, y, feature_mask):\n", "    selected = X[:, feature_mask == 1]\n", "    if selected.shape[1] == 0:\n", "        return 0\n", "    clf = GradientBoostingClassifier()\n", "    X_train, X_val, y_train, y_val = train_test_split(selected, y, test_size=0.3, random_state=42)\n", "    clf.fit(X_train, y_train)\n", "    y_pred = clf.predict(X_val)\n", "    return f1_score(y_val, y_pred)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Genetic Algorithm\n", "def genetic_algorithm(X, y, pop_size=20, generations=20):\n", "    dim = X.shape[1]\n", "    population = np.random.randint(0, 2, (pop_size, dim))\n", "    for gen in range(generations):\n", "        fitness = [evaluate_fitness(X, y, ind) for ind in population]\n", "        sorted_idx = np.argsort(fitness)[::-1]\n", "        population = population[sorted_idx]\n", "        new_pop = population[:2]  # elitism\n", "        while len(new_pop) < pop_size:\n", "            p1, p2 = population[np.random.randint(0, 10, 2)]\n", "            cross = np.random.randint(1, dim-1)\n", "            child = np.concatenate([p1[:cross], p2[cross:]])\n", "            if np.random.rand() < 0.1:\n", "                child[np.random.randint(0, dim)] ^= 1\n", "            new_pop.append(child)\n", "        population = np.array(new_pop)\n", "    best = population[0]\n", "    best_f1 = evaluate_fitness(X, y, best)\n", "    return best, best_f1"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Run GA\n", "best_features_ga, best_score_ga = genetic_algorithm(X, y)\n", "print(f\"GA - Best F1 Score: {best_score_ga:.4f}, Selected Features: {np.sum(best_features_ga)}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["> \ud83d\udcdd The Jaya and ROA algorithms can be implemented similarly. Add them here if needed or use external packages like `mealpy`."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save selected feature mask\n", "with open(\"selected_features_ga.pkl\", \"wb\") as f:\n", "    pickle.dump({\"mask\": best_features_ga}, f)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}